// Copyright 2014-2017 Oxford University Innovation Limited and the authors of InfiniTAM

#pragma once

#ifndef __METALC__

#include "../../Utils/ITMMath.h"
#include "../../../ORUtils/Image.h"

namespace ITMLib {
/** 渲染结果。用于SceneReconstruction和Visualisation。怎么用于SceneReconstruction？？？
 * Stores the render state used by the SceneReconstruction and Visualisation engines.
*/
class ITMRenderState {
 public:
  /** 记录raycating中每条ray的最小和最大深度。
   * 从而在raycasting中更快搜索ray跟三维模型的交点。
   * 应该在 raycasting之前更新。  // TODO:可以设置成private吗？
   * Gives the raycasting operations an idea of the depth range to cover
   * Each pixel contains an expected minimum and maximum depth. The raycasting step would use this information to 
   *    reduce the range for searching an intersection with the actual surface. Should be updated by a 
   *    ITMLib::Engine::ITMVisualisationEngine before any raycasting operation.
  */
  ORUtils::Image<Vector2f> *renderingRangeImage;  

  /** raycasting的结果。每个像素记录对应ray跟三维模型的交点（使用voxel坐标）。
   * 第四个通道=对应ray找到等值面的置信度（用邻域voxel插值出来的）+1，找不到则为0。
   * 英文注释说是raycasting的“by-product”，那raycasting的真正输出是什么？？？
   * Float rendering output of the scene, containing the 3D locations in the world generated by the raycast. 
   * This is typically created as a by-product of raycasting operations.
  */
  ORUtils::Image<Vector4f> *raycastResult;

  ORUtils::Image<Vector4f> *forwardProjection;
  ORUtils::Image<int> *fwdProjMissingPoints;
  int noFwdProjMissingPoints;

  ORUtils::Image<Vector4u> *raycastImage;
  /**
   * @brief Construct a new ITMRenderState object
   * @param[in] imgSize raycasting的图像大小
   * @param[in] vf_min 视锥的最近距离
   * @param[in] vf_max 视锥的最远距离
   * @param[in] memoryType 内存类型：GPU or CPU
   */
  ITMRenderState(const Vector2i &imgSize, float vf_min, float vf_max, MemoryDeviceType memoryType) {
    renderingRangeImage = new ORUtils::Image<Vector2f>(imgSize, memoryType);
    raycastResult = new ORUtils::Image<Vector4f>(imgSize, memoryType);
    forwardProjection = new ORUtils::Image<Vector4f>(imgSize, memoryType);
    fwdProjMissingPoints = new ORUtils::Image<int>(imgSize, memoryType);
    raycastImage = new ORUtils::Image<Vector4u>(imgSize, memoryType);
    // 初始化renderingRangeImage中的每个像素的最大最小深度 为 视锥的范围
    ORUtils::Image<Vector2f> *buffImage = new ORUtils::Image<Vector2f>(imgSize, MEMORYDEVICE_CPU);

    Vector2f v_lims(vf_min, vf_max);
    for (int i = 0; i < imgSize.x * imgSize.y; i++) 
      buffImage->GetData(MEMORYDEVICE_CPU)[i] = v_lims;

    if (memoryType == MEMORYDEVICE_CUDA) {  // TODO:这里会有问题吧？？？如果memoryType=CUDA，又令COMPILE_WITHOUT_CUDA=1
#ifndef COMPILE_WITHOUT_CUDA
      renderingRangeImage->SetFrom(buffImage, ORUtils::MemoryBlock<Vector2f>::CPU_TO_CUDA);
#endif
    } else  //TODO：CPU直接给renderingRangeImage赋值就好，不用加个中间商buffImage
      renderingRangeImage->SetFrom(buffImage, ORUtils::MemoryBlock<Vector2f>::CPU_TO_CPU); 

    delete buffImage;

    noFwdProjMissingPoints = 0;
  }

  virtual ~ITMRenderState() {
    delete renderingRangeImage;
    delete raycastResult;
    delete forwardProjection;
    delete fwdProjMissingPoints;
    delete raycastImage;
  }
};
}

#endif
