// Copyright 2014-2017 Oxford University Innovation Limited and the authors of InfiniTAM

#include "ITMSwappingEngine_CUDA.h"

#include "../Shared/ITMSwappingEngine_Shared.h"
#include "../../../Objects/RenderStates/ITMRenderState_VH.h"
#include "../../../Utils/ITMCUDAUtils.h"
using namespace ITMLib;

namespace { // 这里先声明函数。实现（或者叫定义）在最后面 // TODO: 为啥要加个namespace呢？
__global__ void buildListToSwapIn_device(int *neededEntryIDs, int *noNeededEntries, ITMHashSwapState *swapStates,
                                         int noTotalEntries);

template <class TVoxel>
__global__ void integrateOldIntoActiveData_device(TVoxel *localVBA, ITMHashSwapState *swapStates,
                                                  TVoxel *syncedVoxelBlocks_local, int *neededEntryIDs_local,
                                                  ITMHashEntry *hashTable, int maxW);

__global__ void buildListToSwapOut_device(int *neededEntryIDs, int *noNeededEntries, ITMHashSwapState *swapStates,
                                          ITMHashEntry *hashTable, uchar *entriesVisibleType, int noTotalEntries);

__global__ void buildListToClean_device(int *neededEntryIDs, int *noNeededEntries, ITMHashEntry *hashTable,
                                        uchar *entriesVisibleType, int noTotalEntries);

template <class TVoxel>
__global__ void cleanMemory_device(int *voxelAllocationList, int *noAllocatedVoxelEntries, ITMHashSwapState *swapStates,
                                   ITMHashEntry *hashTable, TVoxel *localVBA, int *neededEntryIDs_local,
                                   int noNeededEntries);

template <class TVoxel>
__global__ void cleanMemory_device(int *voxelAllocationList, int *noAllocatedVoxelEntries, ITMHashEntry *hashTable,
                                   TVoxel *localVBA, int *neededEntryIDs_local, int noNeededEntries);

template<class TVoxel>
__global__ void cleanVBA(int *neededEntryIDs_local, ITMHashEntry *hashTable, TVoxel *localVBA);

template <class TVoxel>
__global__ void moveActiveDataToTransferBuffer_device(TVoxel *syncedVoxelBlocks_local, bool *hasSyncedData_local,
                                                      int *neededEntryIDs_local, ITMHashEntry *hashTable,
                                                      TVoxel *localVBA);
}

template<class TVoxel>
ITMSwappingEngine_CUDA<TVoxel, ITMVoxelBlockHash>::ITMSwappingEngine_CUDA(void) {
  ORcudaSafeCall(cudaMalloc((void **) &noAllocatedVoxelEntries_device, sizeof(int)));
  ORcudaSafeCall(cudaMalloc((void **) &noNeededEntries_device, sizeof(int)));
  ORcudaSafeCall(cudaMalloc((void **) &entriesToClean_device, SDF_LOCAL_BLOCK_NUM * sizeof(int)));
}

template<class TVoxel>
ITMSwappingEngine_CUDA<TVoxel, ITMVoxelBlockHash>::~ITMSwappingEngine_CUDA(void) {
  ORcudaSafeCall(cudaFree(noAllocatedVoxelEntries_device));
  ORcudaSafeCall(cudaFree(noNeededEntries_device));
  ORcudaSafeCall(cudaFree(entriesToClean_device));
}

template<class TVoxel>
int ITMSwappingEngine_CUDA<TVoxel, ITMVoxelBlockHash>::LoadFromGlobalMemory(ITMScene<TVoxel,
                                                                                     ITMVoxelBlockHash> *scene) {
  //! 准备
  ITMGlobalCache<TVoxel> *globalCache = scene->globalCache;         // swapping所需变量
  ITMHashSwapState *swapStates = globalCache->GetSwapStates(true);  // 数据传输状态
  // device相关变量
  TVoxel *syncedVoxelBlocks_local = globalCache->GetSyncedVoxelBlocks(true);  // device上的transfer buffer
  bool *hasSyncedData_local = globalCache->GetHasSyncedData(true);            // device拿到的voxel
  int *neededEntryIDs_local = globalCache->GetNeededEntryIDs(true);           // device这儿记录是否读取成功
  // global相关变量
  TVoxel *syncedVoxelBlocks_global = globalCache->GetSyncedVoxelBlocks(false);  // host上的transfer buffer
  bool *hasSyncedData_global = globalCache->GetHasSyncedData(false);
  int *neededEntryIDs_global = globalCache->GetNeededEntryIDs(false);
  //! 找出所有要合并的entry id
  dim3 blockSize(256);
  dim3 gridSize((int) ceil((float) scene->index.noTotalEntries / (float) blockSize.x));
  ORcudaSafeCall(cudaMemset(noNeededEntries_device, 0, sizeof(int))); 
  buildListToSwapIn_device << < gridSize, blockSize >> >(neededEntryIDs_local, noNeededEntries_device, swapStates,
      scene->globalCache->noTotalEntries);
  ORcudaKernelCheck;
  //! 将所有要合并的entry对应的block数据读取出来
  int noNeededEntries;
  ORcudaSafeCall(cudaMemcpy(&noNeededEntries, noNeededEntries_device, sizeof(int), cudaMemcpyDeviceToHost));

  if (noNeededEntries > 0) {  // "先找到entry 再读取block"是为了能一次性初始化完整
    // 将要拷贝的entry信息从GPU=>CPU
    noNeededEntries = MIN(noNeededEntries, SDF_TRANSFER_BLOCK_NUM); // 一次性传输大小有限制，默认为0x1000 //TODO:放到上面？？？
    ORcudaSafeCall(cudaMemcpy(neededEntryIDs_global, neededEntryIDs_local, sizeof(int) * noNeededEntries, 
                              cudaMemcpyDeviceToHost));
    // 初始化为0
    memset(syncedVoxelBlocks_global, 0, noNeededEntries * SDF_BLOCK_SIZE3 * sizeof(TVoxel));
    memset(hasSyncedData_global, 0, noNeededEntries * sizeof(bool));
    // 从host的voxel memory拷贝每一个block到host的transfer buffer
    for (int i = 0; i < noNeededEntries; i++) {
      int entryId = neededEntryIDs_global[i];

      if (globalCache->HasStoredData(entryId)) {    // 已经存在Host上的才读取出来。没有读个屁！
        hasSyncedData_global[i] = true;
        memcpy(syncedVoxelBlocks_global + i * SDF_BLOCK_SIZE3, globalCache->GetStoredVoxelBlock(entryId),
               SDF_BLOCK_SIZE3 * sizeof(TVoxel));
      }
    }
    // 将host的transfer buffer 一次性拷贝到 device的transfer buffer，包含 block数据 和 是否成功的数据
    ORcudaSafeCall(cudaMemcpy(hasSyncedData_local, hasSyncedData_global, sizeof(bool) * noNeededEntries, 
                              cudaMemcpyHostToDevice));
    ORcudaSafeCall(cudaMemcpy(syncedVoxelBlocks_local, syncedVoxelBlocks_global,
                              sizeof(TVoxel) * SDF_BLOCK_SIZE3 * noNeededEntries, cudaMemcpyHostToDevice));
  }

  return noNeededEntries;
}

template <class TVoxel>
void ITMSwappingEngine_CUDA<TVoxel, ITMVoxelBlockHash>::IntegrateGlobalIntoLocal(
    ITMScene<TVoxel, ITMVoxelBlockHash> *scene, ITMRenderState *renderState) {
  ITMGlobalCache<TVoxel> *globalCache = scene->globalCache;

  ITMHashEntry *hashTable = scene->index.GetEntries();

  ITMHashSwapState *swapStates = globalCache->GetSwapStates(true);

  TVoxel *syncedVoxelBlocks_local = globalCache->GetSyncedVoxelBlocks(true);
  int *neededEntryIDs_local = globalCache->GetNeededEntryIDs(true);

  TVoxel *localVBA = scene->localVBA.GetVoxelBlocks();

  int noNeededEntries = this->LoadFromGlobalMemory(scene);

  int maxW = scene->sceneParams->maxW;

  if (noNeededEntries > 0) {
    dim3 blockSize(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
    dim3 gridSize(noNeededEntries);

    integrateOldIntoActiveData_device << < gridSize, blockSize >> >(localVBA, swapStates, syncedVoxelBlocks_local,
        neededEntryIDs_local, hashTable, maxW);
    ORcudaKernelCheck;
  }
}

template<class TVoxel>
void ITMSwappingEngine_CUDA<TVoxel, ITMVoxelBlockHash>::SaveToGlobalMemory(ITMScene<TVoxel, ITMVoxelBlockHash> *scene,
                                                                           ITMRenderState *renderState) {
  ITMGlobalCache<TVoxel> *globalCache = scene->globalCache;

  ITMHashSwapState *swapStates = globalCache->GetSwapStates(true);

  ITMHashEntry *hashTable = scene->index.GetEntries();
  uchar *entriesVisibleType = ((ITMRenderState_VH *) renderState)->GetEntriesVisibleType();

  TVoxel *syncedVoxelBlocks_local = globalCache->GetSyncedVoxelBlocks(true);
  bool *hasSyncedData_local = globalCache->GetHasSyncedData(true);
  int *neededEntryIDs_local = globalCache->GetNeededEntryIDs(true);

  TVoxel *syncedVoxelBlocks_global = globalCache->GetSyncedVoxelBlocks(false);
  bool *hasSyncedData_global = globalCache->GetHasSyncedData(false);
  int *neededEntryIDs_global = globalCache->GetNeededEntryIDs(false);

  TVoxel *localVBA = scene->localVBA.GetVoxelBlocks();
  int *voxelAllocationList = scene->localVBA.GetAllocationList();

  int noTotalEntries = globalCache->noTotalEntries;

  dim3 blockSize, gridSize;
  int noNeededEntries;

  {
    blockSize = dim3(256);
    gridSize = dim3((int) ceil((float) scene->index.noTotalEntries / (float) blockSize.x));

    ORcudaSafeCall(cudaMemset(noNeededEntries_device, 0, sizeof(int)));

    buildListToSwapOut_device << < gridSize, blockSize >> >(neededEntryIDs_local, noNeededEntries_device, swapStates,
        hashTable, entriesVisibleType, noTotalEntries);
    ORcudaKernelCheck;

    ORcudaSafeCall(cudaMemcpy(&noNeededEntries, noNeededEntries_device, sizeof(int), cudaMemcpyDeviceToHost));
  }

  if (noNeededEntries > 0) {
    noNeededEntries = MIN(noNeededEntries, SDF_TRANSFER_BLOCK_NUM);
    {
      blockSize = dim3(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
      gridSize = dim3(noNeededEntries);

      moveActiveDataToTransferBuffer_device << < gridSize, blockSize >> >(syncedVoxelBlocks_local, hasSyncedData_local,
          neededEntryIDs_local, hashTable, localVBA);
      ORcudaKernelCheck;
    }

    {
      blockSize = dim3(256);
      gridSize = dim3((int) ceil((float) noNeededEntries / (float) blockSize.x));

      ORcudaSafeCall(cudaMemcpy(noAllocatedVoxelEntries_device,
                                &scene->localVBA.lastFreeBlockId,
                                sizeof(int),
                                cudaMemcpyHostToDevice));

      cleanMemory_device <<< gridSize, blockSize >> >(voxelAllocationList, noAllocatedVoxelEntries_device, swapStates, hashTable, localVBA,
          neededEntryIDs_local, noNeededEntries);
      ORcudaKernelCheck;

      ORcudaSafeCall(cudaMemcpy(&scene->localVBA.lastFreeBlockId,
                                noAllocatedVoxelEntries_device,
                                sizeof(int),
                                cudaMemcpyDeviceToHost));
      scene->localVBA.lastFreeBlockId = MAX(scene->localVBA.lastFreeBlockId, 0);
      scene->localVBA.lastFreeBlockId = MIN(scene->localVBA.lastFreeBlockId, SDF_LOCAL_BLOCK_NUM);
    }

    ORcudaSafeCall(cudaMemcpy(neededEntryIDs_global,
                              neededEntryIDs_local,
                              sizeof(int) * noNeededEntries,
                              cudaMemcpyDeviceToHost));
    ORcudaSafeCall(cudaMemcpy(hasSyncedData_global,
                              hasSyncedData_local,
                              sizeof(bool) * noNeededEntries,
                              cudaMemcpyDeviceToHost));
    ORcudaSafeCall(cudaMemcpy(syncedVoxelBlocks_global,
                              syncedVoxelBlocks_local,
                              sizeof(TVoxel) * SDF_BLOCK_SIZE3 * noNeededEntries,
                              cudaMemcpyDeviceToHost));

    for (int entryId = 0; entryId < noNeededEntries; entryId++) {
      if (hasSyncedData_global[entryId])
        globalCache->SetStoredData(neededEntryIDs_global[entryId],
                                   syncedVoxelBlocks_global + entryId * SDF_BLOCK_SIZE3);
    }
  }
}

template<class TVoxel>
void ITMSwappingEngine_CUDA<TVoxel, ITMVoxelBlockHash>::CleanLocalMemory(ITMScene<TVoxel, ITMVoxelBlockHash> *scene,
                                                                         ITMRenderState *renderState) {
  ITMHashEntry *hashTable = scene->index.GetEntries();
  uchar *entriesVisibleType = ((ITMRenderState_VH *) renderState)->GetEntriesVisibleType();

  TVoxel *localVBA = scene->localVBA.GetVoxelBlocks();
  int *voxelAllocationList = scene->localVBA.GetAllocationList();

  dim3 blockSize, gridSize;
  int noNeededEntries;

  {
    blockSize = dim3(256);
    gridSize = dim3((int) ceil((float) scene->index.noTotalEntries / (float) blockSize.x));

    ORcudaSafeCall(cudaMemset(noNeededEntries_device, 0, sizeof(int)));

    buildListToClean_device <<< gridSize, blockSize >> >(entriesToClean_device, noNeededEntries_device, hashTable, entriesVisibleType, scene->index.noTotalEntries);

    ORcudaSafeCall(cudaMemcpy(&noNeededEntries, noNeededEntries_device, sizeof(int), cudaMemcpyDeviceToHost));
  }

  if (noNeededEntries > 0) {
    noNeededEntries = MIN(noNeededEntries, SDF_TRANSFER_BLOCK_NUM);
    {
      blockSize = dim3(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
      gridSize = dim3(noNeededEntries);

      cleanVBA << < gridSize, blockSize >> >(entriesToClean_device, hashTable, localVBA);
    }

    {
      blockSize = dim3(256);
      gridSize = dim3((int) ceil((float) noNeededEntries / (float) blockSize.x));

      ORcudaSafeCall(cudaMemcpy(noAllocatedVoxelEntries_device,
                                &scene->localVBA.lastFreeBlockId,
                                sizeof(int),
                                cudaMemcpyHostToDevice));

      cleanMemory_device <<< gridSize, blockSize >> >(voxelAllocationList, noAllocatedVoxelEntries_device, hashTable, localVBA, entriesToClean_device, noNeededEntries);

      ORcudaSafeCall(cudaMemcpy(&scene->localVBA.lastFreeBlockId,
                                noAllocatedVoxelEntries_device,
                                sizeof(int),
                                cudaMemcpyDeviceToHost));
      scene->localVBA.lastFreeBlockId = MAX(scene->localVBA.lastFreeBlockId, 0);
      scene->localVBA.lastFreeBlockId = MIN(scene->localVBA.lastFreeBlockId, SDF_LOCAL_BLOCK_NUM);
    }
  }
}

namespace { // 这里是实现。声明在最前面
__global__ void buildListToSwapIn_device(int *neededEntryIDs, int *noNeededEntries, ITMHashSwapState *swapStates,
                                         int noTotalEntries) {  // TODO:下次从这儿开始
  int targetIdx = threadIdx.x + blockIdx.x * blockDim.x;
  if (targetIdx > noTotalEntries - 1) return;

  __shared__ bool shouldPrefix;

  shouldPrefix = false;
  __syncthreads();

  bool isNeededId = (swapStates[targetIdx].state == 1);

  if (isNeededId) shouldPrefix = true;
  __syncthreads();

  if (shouldPrefix) {
    int offset = computePrefixSum_device<int>(isNeededId, noNeededEntries, blockDim.x * blockDim.y, threadIdx.x);
    if (offset != -1 && offset < SDF_TRANSFER_BLOCK_NUM) neededEntryIDs[offset] = targetIdx;
  }
}

__global__ void buildListToSwapOut_device(int *neededEntryIDs, int *noNeededEntries, ITMHashSwapState *swapStates,
                                          ITMHashEntry *hashTable, uchar *entriesVisibleType, int noTotalEntries) {
  int targetIdx = threadIdx.x + blockIdx.x * blockDim.x;
  if (targetIdx > noTotalEntries - 1) return;

  __shared__ bool shouldPrefix;

  shouldPrefix = false;
  __syncthreads();

  ITMHashSwapState &swapState = swapStates[targetIdx];

  bool isNeededId = (swapState.state == 2 &&
      hashTable[targetIdx].ptr >= 0 && entriesVisibleType[targetIdx] == 0);

  if (isNeededId) shouldPrefix = true;
  __syncthreads();

  if (shouldPrefix) {
    int offset = computePrefixSum_device<int>(isNeededId, noNeededEntries, blockDim.x * blockDim.y, threadIdx.x);
    if (offset != -1 && offset < SDF_TRANSFER_BLOCK_NUM) neededEntryIDs[offset] = targetIdx;
  }
}

template<class TVoxel>
__global__ void cleanMemory_device(int *voxelAllocationList,
                                   int *noAllocatedVoxelEntries,
                                   ITMHashSwapState *swapStates,
                                   ITMHashEntry *hashTable,
                                   TVoxel *localVBA,
                                   int *neededEntryIDs_local,
                                   int noNeededEntries) {
  int locId = threadIdx.x + blockIdx.x * blockDim.x;

  if (locId > noNeededEntries - 1) return;

  int entryDestId = neededEntryIDs_local[locId];

  swapStates[entryDestId].state = 0;

  int vbaIdx = atomicAdd(&noAllocatedVoxelEntries[0], 1);
  if (vbaIdx < SDF_LOCAL_BLOCK_NUM - 1) {
    voxelAllocationList[vbaIdx + 1] = hashTable[entryDestId].ptr;
    hashTable[entryDestId].ptr = -1;
  }
}

__global__ void buildListToClean_device(int *neededEntryIDs,
                                        int *noNeededEntries,
                                        ITMHashEntry *hashTable,
                                        uchar *entriesVisibleType,
                                        int noTotalEntries) {
  int targetIdx = threadIdx.x + blockIdx.x * blockDim.x;
  if (targetIdx > noTotalEntries - 1) return;

  __shared__ bool shouldPrefix;

  shouldPrefix = false;
  __syncthreads();

  bool isNeededId = hashTable[targetIdx].ptr >= 0 && entriesVisibleType[targetIdx] == 0;

  if (isNeededId) shouldPrefix = true;
  __syncthreads();

  if (shouldPrefix) {
    int offset = computePrefixSum_device<int>(isNeededId, noNeededEntries, blockDim.x * blockDim.y, threadIdx.x);
    if (offset != -1 && offset < SDF_TRANSFER_BLOCK_NUM) neededEntryIDs[offset] = targetIdx;
  }
}

template<class TVoxel>
__global__ void cleanMemory_device(int *voxelAllocationList,
                                   int *noAllocatedVoxelEntries,
                                   ITMHashEntry *hashTable,
                                   TVoxel *localVBA,
                                   int *neededEntryIDs_local,
                                   int noNeededEntries) {
  int locId = threadIdx.x + blockIdx.x * blockDim.x;

  if (locId > noNeededEntries - 1) return;

  int entryDestId = neededEntryIDs_local[locId];

  int vbaIdx = atomicAdd(&noAllocatedVoxelEntries[0], 1);
  if (vbaIdx < SDF_LOCAL_BLOCK_NUM - 1) {
    voxelAllocationList[vbaIdx + 1] = hashTable[entryDestId].ptr;
    hashTable[entryDestId].ptr = -2;
  }
}

template<class TVoxel>
__global__ void cleanVBA(int *neededEntryIDs_local, ITMHashEntry *hashTable, TVoxel *localVBA) {
  int entryDestId = neededEntryIDs_local[blockIdx.x];

  ITMHashEntry &hashEntry = hashTable[entryDestId];

  TVoxel *srcVB = localVBA + hashEntry.ptr * SDF_BLOCK_SIZE3;

  int vIdx = threadIdx.x + threadIdx.y * SDF_BLOCK_SIZE + threadIdx.z * SDF_BLOCK_SIZE * SDF_BLOCK_SIZE;
  srcVB[vIdx] = TVoxel();
}

template<class TVoxel>
__global__ void moveActiveDataToTransferBuffer_device(TVoxel *syncedVoxelBlocks_local,
                                                      bool *hasSyncedData_local,
                                                      int *neededEntryIDs_local,
                                                      ITMHashEntry *hashTable,
                                                      TVoxel *localVBA) {
  int entryDestId = neededEntryIDs_local[blockIdx.x];

  ITMHashEntry &hashEntry = hashTable[entryDestId];

  TVoxel *dstVB = syncedVoxelBlocks_local + blockIdx.x * SDF_BLOCK_SIZE3;
  TVoxel *srcVB = localVBA + hashEntry.ptr * SDF_BLOCK_SIZE3;

  int vIdx = threadIdx.x + threadIdx.y * SDF_BLOCK_SIZE + threadIdx.z * SDF_BLOCK_SIZE * SDF_BLOCK_SIZE;
  dstVB[vIdx] = srcVB[vIdx];
  srcVB[vIdx] = TVoxel();

  if (vIdx == 0) hasSyncedData_local[blockIdx.x] = true;
}

template<class TVoxel>
__global__ void integrateOldIntoActiveData_device(TVoxel *localVBA,
                                                  ITMHashSwapState *swapStates,
                                                  TVoxel *syncedVoxelBlocks_local,
                                                  int *neededEntryIDs_local,
                                                  ITMHashEntry *hashTable,
                                                  int maxW) {
  int entryDestId = neededEntryIDs_local[blockIdx.x];

  TVoxel *srcVB = syncedVoxelBlocks_local + blockIdx.x * SDF_BLOCK_SIZE3;
  TVoxel *dstVB = localVBA + hashTable[entryDestId].ptr * SDF_BLOCK_SIZE3;

  int vIdx = threadIdx.x + threadIdx.y * SDF_BLOCK_SIZE + threadIdx.z * SDF_BLOCK_SIZE * SDF_BLOCK_SIZE;

  CombineVoxelInformation<TVoxel::hasColorInformation, TVoxel>::compute(srcVB[vIdx], dstVB[vIdx], maxW);

  if (vIdx == 0) swapStates[entryDestId].state = 2;
}

}
